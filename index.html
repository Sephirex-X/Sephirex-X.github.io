<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5YCW3TPD6K"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-5YCW3TPD6K');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lingyu Xiao</title>

  <meta name="author" content="Lingyu Xiao">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" type="image/svg" href="static/images/seu.svg">
  <link rel="stylesheet" type="text/css" href="static/css/stylesheet.css">
  <link rel="stylesheet" type="text/css" href="static/css/fontawesome.all.min.css">

  <script src="static/js/fontawesome.all.min.js"></script>

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Lingyu Xiao (Sephirex)
                  </p>
                  <p> I am currently a MSc student at the School of Automation, Southeast University, China.
                    Expected to graduate in 2025.
                    <!-- I obtained BEng in Automation (Transportation Information and Controls) from Chang'an University,
                    China, in 2022 with Summa Cum Laude. -->
                  </p>
                  <p>
                    My research interests lie in:
                  <p>
                    &#9658 Perception & decision-making in autonomous driving and robotics.
                  </p>
                  <p>
                    &#9658 Multi-modal machine learning (e.g., vision and language).
                  </p>
                  Lots of my projects during undergraduate are focus on embedded systems in robotics (ROS, gazebo, etc.)
                  </p>
                  <p style="text-align:center">
                    <span class="link-block">
                      <a href="mailti:lyhsiao@seu.edu.cn">
                        <span class="icon"><i class="fa fa-envelope"></i></span>
                        <span>lyhsiao@seu.edu.cn</span>
                      </a>
                    </span>&nbsp/&nbsp
                    <span class="link-block">
                      <a href="https://scholar.google.com/citations?user=bpmipaMAAAAJ&hl=zh-CN">
                        <span class="icon"><i class="fa fa-graduation-cap"></i></span>
                        <span>Google Scholar</span>
                      </a>
                    </span>&nbsp/&nbsp
                    <span class="link-block">
                      <a href="https://github.com/Sephirex-X">
                        <span class="icon"><i class="fab fa-github"></i></span>
                        <span>Github</span>
                      </a>
                    </span>
                  </p>
                </td>
                <!-- <td style="padding:2.5%;width:45%;max-width:40%;">
                  <a href="./static/images/xly.jpg"><img style="width:80%;max-width:80%;border-radius: 20px;"
                      alt="profile photo" src="./static/images/xly.jpg" class="hoverZoomLink"></a>
                </td> -->
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="./static/images/xly.jpg"><img
                      style="width:80%;max-width:80%;object-fit: cover; border-radius: 10%;" alt="profile photo"
                      src="./static/images/xly.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- News -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                    <!-- <strong>Honors</strong> -->
                  </p>
                  <ul>
                    <li>
                    [Mar/2025] One First-Authored Paper Accepted by <strong><em>Pattern Recognition</em></strong>!
                    <li>
                    [Jan/2025] One First-Authored Paper Accepted by <strong><em>ICRA</em></strong>!
                    <li>
                    [Oct/2023] Start my internship at Baidu, VIS, Shanghai.
                    <li>
                    [Oct/2023] Travel to <strong><em>ICCV 2023</em></strong> in Paris, France.
                    <li>
                    [Jul/2023] One First-Authored Paper Accepted by <strong><em>ICCV</em></strong>!
                    <li>
                    [Sep/2022] Start my MSc at Southeast University, China.
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Publications -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    *Equal contribution. Some papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Multi-modal machine learning -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <h2>Multi-modal Machine Learning</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <!-- vlm classification -->
                  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                    <td style="padding:10px;width:30%;vertical-align:middle">
                      <!-- <img src='./static/images/easychauffeur.jpg' alt="game" width=100% style="border-style: none"> -->
                      <img src='./static/images/vlm-cls.jpg' alt="game" width=100% style="border-style: none">
                    </td>
                    <td style="padding:10px;width:70%;vertical-align:middle">
                      <strong>
                        <papertitle>Revisiting MLLMs: An In-Depth Analysis of Image Classification Abilities
                        </papertitle>
                      </strong>
                      <br>
                      Huan Liu*,
                      <strong>Lingyu Xiao*</strong>,
                      <a href="https://scholar.google.com/citations?user=lpFrrs8AAAAJ&hl=zh-CN">Jiang-jiang Liu</a>,
                      Xiaofan Li,
                      Ze Feng,
                      <a href="https://scholar.google.com/citations?user=z5O3DLcAAAAJ&hl=zh-CN">Sen Yang</a>,
                      <a href="https://jingdongwang2017.github.io/">Jingdong Wang</a>.
                      <br>
                      <em> Preprint, Arxiv </em>, 2024
                      <br>
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2412.16418" target="_blank">
                          <span class="icon"><i class="fas fa-file-pdf"></i></span>
                          <span>Paper</span>
                        </a>
                      </span>
                      <br>
                      <br>
                      Why some VLMs are bad at image classification while others are not?
                    </td>
                  </tr>
              </table>
              <!-- Decision-Making in Autonomous Driving & Robotic -->
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:10px;width:100%;vertical-align:middle">
                      <h2>Decision-Making in Autonomous Driving</h2>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <!-- LatentDriver -->
                      <tr onmouseout="smerf_stop()" onmouseover="smerf_start()" bgcolor="#ffffd0">
                        <td style="padding:10px;width:30%;vertical-align:middle">
                          <!-- <img id="test" src='./static/images/latentdriver.jpg' alt="game" width=100%
        style="border-style: none"> -->
                          <video width=100% muted autoplay loop>
                            <source src='static/images/latentdriver.mov' type="video/mp4" width=100%>
                          </video>
                        </td>
                        <td style="padding:10px;width:70%;vertical-align:middle">
                          <strong href="https://Sephirex-X.github.io/LatentDriver/">
                            <papertitle>Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous
                              Driving
                            </papertitle>
                          </strong>
                          <br>
                          <strong>Lingyu Xiao</strong>,
                          <a href="https://scholar.google.com/citations?user=lpFrrs8AAAAJ&hl=zh-CN">Jiang-jiang Liu</a>,
                          <a href="https://scholar.google.com/citations?user=z5O3DLcAAAAJ&hl=zh-CN"><a
                              href="https://scholar.google.com/citations?user=z5O3DLcAAAAJ&hl=zh-CN">Sen Yang</a></a>,
                          Xiaofan Li,
                          <a href="https://shuluoshu.github.io//">Xiaoqing Ye</a>,
                          <a href="https://scholar.google.com/citations?user=PMzEsJgAAAAJ&hl=zh-CN">Wankou Yang</a>,
                          <a href="https://jingdongwang2017.github.io/">Jingdong Wang</a>.
                          <br>
                          <em>International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2025 &nbsp
                          <br>
                          <span class="link-block">
                            <a href="https://arxiv.org/pdf/2409.15730">
                              <span class="icon"><i class="fas fa-file-pdf"></i></span>
                              <span>Paper</span>
                            </a>
                          </span>/
                          <span class="link-block">
                            <a href="https://Sephirex-X.github.io/LatentDriver/">
                              <span class="icon"><i class="fa fa-columns"></i></span>
                              <span>Page</span>
                            </a>
                          </span>/
                          <span class="link-block">
                            <a href="https://github.com/Sephirex-X/LatentDriver">
                              <span class="icon"><i class="fab fa-github"></i></span>
                              <span>Code</span>
                            </a>
                          </span>
                          <br>
                          <br>
                          Deriving decisions from an autoregressive latent world model through multiple probabilistic
                          hypotheses. Expert-level performance on Waymax.
                        </td>
                      </tr>
                      <!-- Easy -->
                      <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                        <td style="padding:10px;width:30%;vertical-align:middle">
                          <!-- <img src='./static/images/easychauffeur.jpg' alt="game" width=100% style="border-style: none"> -->
                          <video width=100% muted autoplay loop>
                            <source src='static/images/easy.mp4' type="video/mp4" width=100%>
                          </video>
                        </td>
                        <td style="padding:10px;width:70%;vertical-align:middle">
                          <strong>
                            <papertitle>EasyChauffeur: A Baseline Advancing Simplicity and Efficiency on Waymax
                            </papertitle>
                          </strong>
                          <br>
                          <strong>Lingyu Xiao</strong>,
                          <a href="https://scholar.google.com/citations?user=lpFrrs8AAAAJ&hl=zh-CN">Jiang-jiang Liu</a>,
                          <a href="https://shuluoshu.github.io//">Xiaoqing Ye</a>,
                          <a href="https://scholar.google.com/citations?user=PMzEsJgAAAAJ&hl=zh-CN">Wankou Yang</a>,
                          <a href="https://jingdongwang2017.github.io/">Jingdong Wang</a>.
                          <br>
                          <em> Preprint, Arxiv </em>, 2024
                          <br>
                          <span class="link-block">
                            <a href="https://arxiv.org/pdf/2408.16375" target="_blank">
                              <span class="icon"><i class="fas fa-file-pdf"></i></span>
                              <span>Paper</span>
                            </a>
                          </span>/
                          <span class="link-block">
                            <a href="https://drive.google.com/drive/folders/1LpAeBZJzXb7Srgq0fTY9KC6DJY6XjajD"
                              target="_blank">
                              <span class="icon"><i class="fa-solid fa-database"></i></span>
                              <span>Supp. Videos</span>
                            </a>
                          </span>
                          <br>
                          <br>
                          Training strategies, data efficiency, and robust evaluation are equally important in learning
                          based planner.
                        </td>
                      </tr>
                  </table>

                  <!-- Perception in Autonomous Driving & Robotic -->
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:10px;width:100%;vertical-align:middle">
                          <h2>Perception in Autonomous Driving & Robotics</h2>
                        </td>
                      </tr>
                    </tbody>
                  </table>


                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <!-- UDA -->
                          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                            <td style="padding:10px;width:30%;vertical-align:middle">
                              <!-- <img src='./static/images/uda.jpg' alt="game" width=100% style="border-style: none"> -->
                              <video width=100% muted autoplay loop>
                                <source src='static/images/uda.mp4' type="video/mp4" width=100%>
                              </video>
                            </td>
                            <td style="padding:10px;width:70%;vertical-align:middle">
                              <strong>
                                <papertitle>Domain Adaptive Depth Completion via Spatial-Error Consistency</papertitle>
                              </strong>
                              <br>
                              <strong>Lingyu Xiao</strong>,
                              Jinhui Wu,
                              <a href="https://junjh.github.io/">Junjie Hu</a>,
                              Ziyu Li,
                              <a href="https://scholar.google.com/citations?user=PMzEsJgAAAAJ&hl=zh-CN">Wankou Yang</a>.
                              <br>
                              <em> Pattern Recognition (<strong>PR</strong>)</em>, 2025
                              <br>
                              <br>
                              Addressesing the UDA problem in depth completion based on a domain/structural-agnostic
                              property.
                            </td>
                          </tr>

                          <!-- ADNet -->
                          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()" bgcolor="#ffffd0">
                            <td style="padding:10px;width:30%;vertical-align:middle">
                              <!-- <img src='./static/images/adnet.jpg' alt="lane" width=100% style="border-style: none"> -->
                              <video width=100% muted autoplay loop>
                                <source src='static/images/adnet.mp4' type="video/mp4" width=100%>
                              </video>
                            </td>
                            <td style="padding:10px;width:70%;vertical-align:middle">
                              <strong>
                                <papertitle>ADNet: Lane Shape Prediction via Anchor Decomposition</papertitle>
                              </strong>
                              <br>
                              <strong>Lingyu Xiao</strong>,
                              <a href="https://implus.github.io/">Xiang Li</a>,
                              <a href="https://scholar.google.com/citations?user=z5O3DLcAAAAJ&hl=zh-CN">Sen Yang</a>,
                              <a href="https://scholar.google.com/citations?user=PMzEsJgAAAAJ&hl=zh-CN">Wankou Yang</a>.
                              <br>
                              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
                              <br>
                              <span class="link-block">
                                <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf"
                                  target="_blank">
                                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                  <span>Paper</span>
                                </a>
                              </span>/
                              <span class="link-block">
                                <a href="static/docs/adnet-poster.pdf" target="_blank">
                                  <span class="icon"><i class="fa fa-columns"></i></span>
                                  <span>Poster</span>
                                </a>
                              </span>/
                              <span class="link-block">
                                <a href="https://github.com/Sephirex-X/ADNet" target="_blank">
                                  <span class="icon"><i class="fab fa-github"></i></span>
                                  <span>Code</span>
                                </a>
                              </span>
                              <br>
                              <br>
                              Making the line anchor learnable in anchor-based lane detection methods. Achieving SOTA on
                              VIL-100.
                            </td>
                          </tr>


                      </table>

                      <!-- Projects -->
                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr>
                            <td style="padding:10px;width:100%;vertical-align:middle">
                              <heading>Projects</heading>

                            </td>
                          </tr>
                        </tbody>
                      </table>

                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                            <td style="padding:10px;width:30%;vertical-align:middle">
                              <video width=100% muted autoplay loop>
                                <source src='static/images/robosummary.mp4' type="video/mp4" width=100%>
                              </video>
                            </td>
                            <td style="padding:10px;width:70%;vertical-align:middle">
                              <strong>
                                <papertitle>Line-Following and Treasure-Hunting Robot</papertitle>
                              </strong>
                              <br>
                              <em>RoboCup Competition, 2021 National 1st Prize in Robot Tourism Group</em>
                              <br>
                              Techniques: Electronic design, Mechanical Design, Control, Computer Vision
                              <br>
                              <span class="link-block">
                                <a href="https://youtu.be/Btgl7rKn-MI" target="_blank">
                                  <span class="icon"><i class="fa-brands fa-youtube"></i></span>
                                  <span>Full Video</span>
                                </a>
                              </span>
                              <br>
                              <br>
                              The project requires robots to complete exploration and treasure-hunting tasks within 180
                              seconds, testing planning, adaptability, positioning, climbing, and obstacle-crossing
                              abilities, while balancing speed and stability.
                            </td>
                          </tr>

                          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                            <td style="padding:10px;width:30%;vertical-align:middle">
                              <video width=100% muted autoplay loop>
                                <source src='static/images/baidu_robo_summary.mp4' type="video/mp4" width=100%>
                              </video>
                            </td>
                            <td style="padding:10px;width:70%;vertical-align:middle">
                              <strong>
                                <papertitle>Autonomous Driving Robot</papertitle>
                              </strong>
                              <!-- <span class="papertitle"></span> -->
                              <br>
                              <em>University Students Intelligent Car Race, 2021 National 3rd Prize in Creative
                                Group</em>
                              <br>
                              Techniques: Computer Vision, Mechanical Design, Control
                              <br>
                              <span class="link-block">
                                <a href="https://youtu.be/mfAHibXcz5M" target="_blank">
                                  <span class="icon"><i class="fa-brands fa-youtube"></i></span>
                                  <span>Full Video</span>
                                </a> /
                                <a href="static/docs/Autonomous_Driving_Robot_report.pdf" target="_blank">
                                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                  <span>Technical Report (Chinese)</span>
                                </a>
                              </span>
                              <br>
                              <br>
                              The competition requires smart cars to follow the lane, identify specific markers, and
                              complete tasks. Finishing is marked by crossing the finish line, and teams are ranked
                              based on total score and time.
                            </td>
                          </tr>

                          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                            <td style="padding:10px;width:30%;vertical-align:middle">
                              <video width=100% muted autoplay loop>
                                <source src='static/images/Drone Landing.mp4' type="video/mp4" width=100%>
                              </video>
                            </td>
                            <td style="padding:10px;width:70%;vertical-align:middle">
                              <strong>
                                <papertitle>Drone Landing with Visual Aid</papertitle>
                              </strong>
                              <br>
                              <em>Course Project</em>
                              <br>
                              Techniques: SLAM, Computer Vision
                              <br>
                              <br>
                              The drone needs to navigate through the unknown maze and land safely.
                            </td>
                          </tr>

                        </tbody>
                      </table>

                      <!-- Honors -->
                      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                          <tr>
                            <td style="padding:10px;width:100%;vertical-align:middle">
                              <heading>Honors</heading>
                              <p>
                                <!-- <strong>Honors</strong> -->
                              </p>
                              <ul>
                                <li> National Scholarship, Ministry of Education of P.R. China, October 2020
                                <li> National 1st Prize, RoboCup Competition, Chinese Association of Automation, October
                                  2021&2020
                                <li> Natoinal 3rd Prize, University Students Intelligent Car Race, Chinese Association
                                  of Automation, 2021
                                <li> 4/4205, WAIC AD Multi-task Learning Challenge, BOSCH China, September 2022
                                  <!-- <li>IEEE Transactions on Intelligent Transportation Systems (T-ITS) -->
                              </ul>
                            </td>
                          </tr>
                        </tbody>
                      </table>
                      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding:10px;width:100%;vertical-align:middle">
                      <heading>Academic Services</heading>
                      <p>
                        <strong>Reviewer</strong>
                      </p>
                      <ul>
                        <li> IEEE International Conference on Robotics and Automation (ICRA)
                        <li> IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
                        <li> IEEE Robotics and Automation Letters (RA-L)
                        <li> IEEE Transactions on Intelligent Vehicles (T-IV)
                        <li>IEEE Transactions on Intelligent Transportation Systems (T-ITS)
                      </ul>
                    </td>
                  </tr>
                </tbody>
              </table> -->

                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr>
                            <td style="padding:0px">
                              <br>
                              <p style="text-align:right;font-size:small;">
                                <br>
                                <a href="https://info.flagcounter.com/bHNc"><img
                                    src="https://s11.flagcounter.com/count/bHNc/bg_FFFFFF/txt_000000/border_CCCCCC/columns_3/maxflags_12/viewers_0/labels_0/pageviews_1/flags_0/percent_0/"
                                    alt="Flag Counter" border="0"></a>
                                <br>
                                <a href="https://jonbarron.info/">Website Template</a>

                              </p>
                            </td>
                          </tr>

                          <tr>
                            <td style="padding:0px">
                              <br>
                              <p style="text-align:left;font-size:small;">
                                <br>

                              </p>
                            </td>
                          </tr>

                        </tbody>
                      </table>
        </td>
      </tr>
  </table>

  <script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function () {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.maxHeight) {
          content.style.maxHeight = null;
        } else {
          content.style.maxHeight = content.scrollHeight + "px";
        }
      });
    }
  </script>

</body>

</html>